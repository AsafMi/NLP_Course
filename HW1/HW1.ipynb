{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# HW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_raw_dataset(split):\n",
    "    words = []\n",
    "    word_type = []\n",
    "    first_word = []\n",
    "    is_entity = []\n",
    "    with open(f\"./data/{split}.txt\") as f:\n",
    "            raw_data  = [line.strip().split(\" \") for line in f.readlines()]\n",
    "            for line in raw_data:\n",
    "                if line[0]=='':\n",
    "                    first_word[-1] = 1\n",
    "                    continue\n",
    "                words.append(line[0])\n",
    "                if len(line)>1:\n",
    "                    word_type.append(line[1])\n",
    "                if len(line)==3:\n",
    "                    is_entity.append(1 if line[2]=='I' else 0)\n",
    "                first_word.append(0)\n",
    "\n",
    "    first_word[0] = 1\n",
    "    if len(is_entity)==0:\n",
    "        return words,word_type,first_word\n",
    "    else:\n",
    "        return words,word_type,first_word,is_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_raw_to_features(words, feature_maps):\n",
    "    feature_representations = []\n",
    "    for word in words:\n",
    "        feature_representations.append([feature(word) for feature in feature_maps])\n",
    "    return feature_representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_1 = lambda word: word[0].isupper()\n",
    "\n",
    "feature_maps = [feature_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words, train_word_type, train_first_word, train_is_entity = load_raw_dataset(\"train\")   \n",
    "eval_words,  eval_word_type,  eval_first_word,  eval_is_entity  = load_raw_dataset('eval')\n",
    "\n",
    "train_is_entity = np.array(train_is_entity)\n",
    "train_X = convert_raw_to_features(train_words, feature_maps)\n",
    "train_X = flatten(train_X)\n",
    "\n",
    "eval_is_entity = np.array(eval_is_entity)\n",
    "eval_X = convert_raw_to_features(eval_words, feature_maps)\n",
    "eval_X = flatten(eval_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train = [list(x) for x in zip(train_word_type, train_X)]\n",
    "feature_train = OneHotEncoder().fit_transform(feature_train)\n",
    "\n",
    "feature_eval = [list(x) for x in zip(eval_word_type, eval_X)]\n",
    "feature_eval = OneHotEncoder().fit_transform(feature_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = SVC()\n",
    "model.fit(feature_train, train_is_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9607555212870971\n",
      "Eval score: 0.9622872941084849\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"Train score: {model.score(feature_train, train_is_entity)}\")\n",
    "print(f\"Eval score: {model.score(feature_eval, eval_is_entity)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to get better grade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_raw_to_features(words,word_type,first_word,feature_maps):\n",
    "    feature_representations = []\n",
    "    for i in range(0, len(words)):\n",
    "        feature_representations.append([feature(words[i],word_type[i],first_word[i]) for feature in feature_maps])\n",
    "    return feature_representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_1(word,word_type,first_word):\n",
    "    if word[0].isupper():\n",
    "        if 'day' in word:\n",
    "            return 0\n",
    "        #if word[-3:] == 'ing':\n",
    "         #   return 0\n",
    "        return 1 \n",
    "#  if word[0].islower():\n",
    "  #      return 0 \n",
    "  \n",
    "    return 0\n",
    "\n",
    "feature_maps = [feature_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words, train_word_type, train_first_word, train_is_entity = load_raw_dataset(\"train\")   \n",
    "eval_words,  train_eval_type, eval_first_word, eval_is_entity  = load_raw_dataset('eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = convert_raw_to_features(train_words, train_word_type, train_first_word, feature_maps)\n",
    "eval_X = convert_raw_to_features(eval_words, train_eval_type, eval_first_word, feature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_is_entity = np.array(train_is_entity)\n",
    "train_X = flatten(train_X)\n",
    "\n",
    "eval_is_entity = np.array(eval_is_entity)\n",
    "eval_X = flatten(eval_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train = [list(x) for x in zip(train_word_type, train_X)]\n",
    "feature_train = OneHotEncoder().fit_transform(feature_train)\n",
    "\n",
    "feature_eval = [list(x) for x in zip(eval_word_type, eval_X)]\n",
    "feature_eval = OneHotEncoder().fit_transform(feature_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = SVC()\n",
    "model.fit(feature_train, train_is_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(f\"Train score: {model.score(feature_train, train_is_entity)}\")\n",
    "print(f\"Eval score: {model.score(feature_eval, eval_is_entity)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_1(word,word_type,first_word):\n",
    "    if word[0].isupper():\n",
    "        return 1 \n",
    "    return 0\n",
    "def feature_2(word,word_type,first_word):\n",
    "    if 'day' in word:\n",
    "        return 0 \n",
    "    return 1\n",
    "def feature_3(word,word_type,first_word):\n",
    "    if first_word and word[0].isupper() and word_type in ['NN','NNS','NNP','NNPS']:\n",
    "        return 0 \n",
    "    return 1\n",
    "feature_maps = [feature_1,feature_2,feature_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9503636658301452\n",
      "Eval score: 0.9487753592149838\n",
      "Wall time: 4min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = SVC()\n",
    "model.fit(feature_train, train_is_entity)\n",
    "print(f\"Train score: {model.score(feature_train, train_is_entity)}\")\n",
    "print(f\"Eval score: {model.score(feature_eval, eval_is_entity)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=14\n",
    "feature_1(train_words[i],train_word_type[i],train_first_word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NNP'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_word_type[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ean'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_words[i][-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'European'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_words[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
